{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pdb\n",
    "import copy\n",
    "from typing import *\n",
    "\n",
    "import collections as cc\n",
    "import sortedcontainers as sc\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "import einops as eo\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import torch as tc\n",
    "import torch.nn as tcn\n",
    "import torch.nn.functional as tcf\n",
    "import torch.optim as tco\n",
    "import torch.distributions as tcd\n",
    "import einops.layers.torch as eol\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "pd.options.display.max_rows = 40\n",
    "pd.options.display.min_rows = 20\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import gym.spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\tdef __init__(self, _epoch = 0, _debug = True):\n",
    "\t\tself.maxSteps = 32\n",
    "\t\tself.lamb = 0.9\n",
    "\t\tself.miniBatchSize = 64\n",
    "\t\tself.delayBatchs = 128\n",
    "\t\tself.totalEpochs = 50\n",
    "\t\tself.testEpochs = 4\n",
    "\t\tself.initEpochs = 20\n",
    "\t\tself.epoch = _epoch\n",
    "\t\tself.lr = 1E-3\n",
    "\t\tself.initlr = 3E-3\n",
    "\t\tself.modelPath = \"./checkpoints/model\"\n",
    "\t\tself.debug = _debug\n",
    "\t\tself.device = tc.device(\"cpu\") if _debug or not tc.cuda.is_available() else tc.device(\"cuda\")\n",
    "\t\tself.mapName = \"4x4\"\n",
    "\t\tself.stateEstimationWeight = 0.5\n",
    "\t\tself.trainingRandomInitState = True\n",
    "\t\tprint(self)\n",
    "\t\n",
    "\tdef stepCheckpoint(self, _epoch = None):\n",
    "\t\tif _epoch is not None:\n",
    "\t\t\tself.epoch = _epoch\n",
    "\t\treturn \"{path}_{epoch:02d}.bin\".format(path = self.modelPath, epoch = self.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayEnvironment:\n",
    "\tdef __init__(self, config: Config):\n",
    "\t\tself.name = \"FrozenLake-v1\"\n",
    "\t\tself.instance = gym.make(self.name, map_name = config.mapName)\n",
    "\t\tself.actionSpace = self.instance.action_space.n\n",
    "\t\tself.stateSpace = self.instance.observation_space.n\n",
    "\t\tself.config = config\n",
    "\t\tself.transProbs, self.transStates, self.transRewards, self.transEnds = self._convertTransMat(3, self.instance.P)\n",
    "\t\tself.instance.render()\n",
    "\t\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"ReplayEnvironment: \" + self.name\n",
    "\t\n",
    "\t# (prob, nstate, rewards, end)\n",
    "\t@tc.no_grad()\n",
    "\tdef _convertTransMat(self, probSpace: int, transDict: Dict[int, Dict[int, List[Tuple[float, int, float, bool]]]]) -> Tuple[tc.FloatTensor, tc.IntTensor, tc.FloatTensor, tc.BoolTensor]:\n",
    "\t\tself.probSpace = probSpace\n",
    "\t\tweights_ = tc.zeros((self.stateSpace, self.actionSpace, probSpace), dtype = tc.float)\n",
    "\t\trewards_ = tc.zeros_like(weights_)\n",
    "\t\tnstates_ = tc.zeros((self.stateSpace, self.actionSpace, probSpace), dtype = tc.int)\n",
    "\t\tends_ = tc.zeros((self.stateSpace, self.actionSpace, probSpace), dtype = tc.bool)\n",
    "\n",
    "\t\tfor k1, s1 in transDict.items():\n",
    "\t\t\tfor k2, s2 in s1.items():\n",
    "\t\t\t\tweights_[k1, k2] = tc.as_tensor([p[0] for p in it.islice(s2, probSpace)], dtype = tc.float)\n",
    "\t\t\t\trewards_[k1, k2] = tc.as_tensor([p[2] for p in it.islice(s2, probSpace)], dtype = tc.float)\n",
    "\t\t\t\tnstates_[k1, k2] = tc.as_tensor([p[1] for p in it.islice(s2, probSpace)], dtype = tc.int)\n",
    "\t\t\t\tends_[k1, k2] = tc.as_tensor([p[3] for p in it.islice(s2, probSpace)], dtype = tc.bool)\n",
    "\t\t\n",
    "\t\treturn weights_, nstates_, rewards_, ends_\n",
    "\t\n",
    "\t# (newState, reward, done)\n",
    "\t@tc.no_grad()\n",
    "\tdef step(self, states: tc.IntTensor, actions: tc.IntTensor) -> Tuple[tc.Tensor, tc.Tensor, tc.Tensor]:\n",
    "\t\tactions = actions.unsqueeze(1).unsqueeze(2).expand((-1, -1, self.probSpace))\n",
    "\t\tstates = states.long()\n",
    "\t\tweights_ = self.transProbs[states].take_along_dim(actions, dim = 1).squeeze(dim = 1)\n",
    "\t\trewards_ = self.transRewards[states].take_along_dim(actions, dim = 1).squeeze(dim = 1)\n",
    "\t\tnstates_ = self.transStates[states].take_along_dim(actions, dim = 1).squeeze(dim = 1)\n",
    "\t\tends_ = self.transEnds[states].take_along_dim(actions, dim = 1).squeeze(dim = 1)\n",
    "\n",
    "\t\tidxes_ = tc.multinomial(weights_, 1, True)\n",
    "\t\treturn nstates_.take_along_dim(idxes_, dim = 1).squeeze(dim = 1), rewards_.take_along_dim(idxes_, dim = 1).squeeze(dim = 1), ends_.take_along_dim(idxes_, dim = 1).squeeze(dim = 1)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorModel(tcn.Module):\n",
    "\tdef __init__(self, env: ReplayEnvironment):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tstateSize_ = env.stateSpace\n",
    "\t\tactionSize_ = env.actionSpace\n",
    "\n",
    "\t\tself.baseModel = tcn.Sequential(\n",
    "\t\t\ttcn.Linear(stateSize_, stateSize_ * 2),\n",
    "\t\t\ttcn.GELU(),\n",
    "\t\t\ttcn.Linear(stateSize_ * 2, stateSize_ * 2),\n",
    "\t\t\ttcn.GELU()\n",
    "\t\t)\n",
    "\n",
    "\t\tself.actionHead = tcn.Sequential(\n",
    "\t\t\ttcn.Linear(stateSize_ * 2, stateSize_ * 2),\n",
    "\t\t\ttcn.GELU(),\n",
    "\t\t\ttcn.Linear(stateSize_ * 2, actionSize_),\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.valueHead = tcn.Linear(stateSize_ * 2, 1)\n",
    "\t\tself.stateSize = stateSize_\n",
    "\t\n",
    "\tdef decayParameters(self):\n",
    "\t\treturn map(lambda x: x[1], filter(lambda x: \"bias\" not in x[0], self.named_parameters()))\n",
    "\n",
    "\tdef nondecayParameters(self):\n",
    "\t\treturn map(lambda x: x[1], filter(lambda x: \"bias\" in x[0], self.named_parameters()))\n",
    "\t\n",
    "\tdef save(self, path):\n",
    "\t\ttc.save(self.state_dict(), path)\n",
    "\n",
    "\tdef load(self, path):\n",
    "\t\tself.load_state_dict(tc.load(path))\n",
    "\n",
    "\tdef forward(self, states: tc.Tensor, invtemp: float = 1.0) -> tc.Tensor:\n",
    "\t\tbaseOutput_ = self.baseModel(tcf.one_hot(states.long(), self.stateSize).float())\n",
    "\t\tlogits_ = self.actionHead(baseOutput_)\n",
    "\t\tactionDist_ = tcd.Categorical(tcf.softmax(logits_ * invtemp, dim = 1))\n",
    "\t\tstateValue_ = self.valueHead(baseOutput_).squeeze()\n",
    "\t\treturn actionDist_, stateValue_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializePolicy(model: ActorModel, env: ReplayEnvironment, config: Config):\n",
    "\topt_ = tco.AdamW([{\"params\": model.decayParameters(), \"weight_decay\": 0.01}, {\"params\": model.nondecayParameters(), \"weight_decay\": 0.0}], config.initlr)\n",
    "\tstates_ = tc.arange(0, env.stateSpace, 1, dtype = tc.int)\n",
    "\tmodel.eval()\n",
    "\twith tc.no_grad():\n",
    "\t\t_, target_ = model(states_)\n",
    "\t\ttarget_ -= target_.min()\n",
    "\t\ttarget_ /= target_.max()\n",
    "\n",
    "\tmodel.train()\n",
    "\tfor i in range(config.initEpochs):\n",
    "\t\tactionDists_, preds_ = model(states_)\n",
    "\t\tloss_ = tcf.mse_loss(preds_, target_)\n",
    "\t\topt_.zero_grad()\n",
    "\t\tloss_.backward()\n",
    "\t\topt_.step()\n",
    "\tprint(\"initialization loss: {0}\".format(loss_.item()))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns [states, values, actions, advantages]\n",
    "@tc.no_grad()\n",
    "def generatePaths(model: ActorModel, env: ReplayEnvironment, config: Config):\n",
    "\tmodel.eval()\n",
    "\n",
    "\tbatchSize_ = config.miniBatchSize * config.delayBatchs\n",
    "\n",
    "\tif config.trainingRandomInitState:\n",
    "\t\tstate_ = tc.randint(env.stateSpace, (batchSize_,))\n",
    "\telse:\n",
    "\t\tstate_ = tc.zeros(batchSize_, dtype = tc.int)\n",
    "\t\n",
    "\tend_ = tc.zeros(batchSize_, dtype = tc.bool)\n",
    "\t\n",
    "\tstates_ = list()\n",
    "\tvalues_ = list()\n",
    "\tadvantages_ = list()\n",
    "\tactions_ = list()\n",
    "\tmasks_ = list()\n",
    "\tvalue_ = None\n",
    "\tadv_ = None\n",
    "\n",
    "\tfor s in range(config.maxSteps):\n",
    "\t\tstates_.append(state_)\n",
    "\t\tmasks_.append(tc.logical_not(end_))\n",
    "\t\tactDists_, estims_ = model(state_)\n",
    "\t\tacts_ = actDists_.sample()\n",
    "\t\t\n",
    "\t\tactions_.append(acts_)\n",
    "\t\tdecayedEstims_ = estims_ * config.lamb\n",
    "\t\tif value_ is not None:\n",
    "\t\t\tvalue_ += decayedEstims_\n",
    "\t\tif adv_ is not None:\n",
    "\t\t\tadv_ += decayedEstims_\n",
    "\t\t\n",
    "\t\tstate_, value_, end_ = env.step(state_, acts_)\n",
    "\t\t\n",
    "\t\t# generate \"partial\" value and advantage for the current\n",
    "\t\tvalues_.append(value_)\n",
    "\t\tadv_ = value_ - estims_\n",
    "\t\tadvantages_.append(adv_)\n",
    "\n",
    "\testims_ = model(state_)[1] * config.lamb\n",
    "\tvalue_ += estims_\n",
    "\tadv_ += estims_\n",
    "\t\n",
    "\tidx_ = tc.cat(masks_).to(tc.bool)\n",
    "\treturn TensorDataset(tc.cat(states_)[idx_], tc.cat(values_)[idx_], tc.cat(actions_)[idx_], tc.cat(advantages_)[idx_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(env: ReplayEnvironment, model: ActorModel, config: Config):\n",
    "\tpaths_ = generatePaths(model, env, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(env: ReplayEnvironment, model: ActorModel, config: Config):\n",
    "\topt_ = tco.AdamW([{\"params\": model.decayParameters(), \"weight_decay\": 0.01}, {\"params\": model.nondecayParameters(), \"weight_decay\": 0.0}], config.lr)\n",
    "\tprint(\"begin epoch {0}, path generation... \".format(config.epoch))\n",
    "\t\n",
    "\tdataloader_ = DataLoader(generatePaths(model, env, config), config.miniBatchSize, shuffle = True, drop_last= True)\n",
    "\tprint(\"begin epoch {0}, training... \".format(config.epoch))\n",
    "\t\n",
    "\tmodel.train()\n",
    "\tlosses_ = list()\n",
    "\tfor batches_, miniBatch_ in enumerate(dataloader_):\n",
    "\t\tstates_, values_, actions_, advantages_ = miniBatch_\n",
    "\t\tassert states_.shape[0] == values_.shape[0] == actions_.shape[0] == advantages_.shape[0] == config.miniBatchSize, \"minibatch size doesn't match required {0}\".format(config.miniBatchSize)\n",
    "\t\t\n",
    "\n",
    "\t\tactionDists_, pvals_ = model(states_)\n",
    "\t\t\n",
    "\t\tloss1_ = -tc.mean(actionDists_.log_prob(actions_) * advantages_)\n",
    "\t\tloss2_ = tcf.mse_loss(pvals_, values_)\n",
    "\t\tloss_ = loss1_ + loss2_ * config.stateEstimationWeight\n",
    "\n",
    "\t\topt_.zero_grad()\n",
    "\t\tloss_.backward()\n",
    "\t\topt_.step()\n",
    "\t\t\n",
    "\t\tlosses_.append(loss_.item())\n",
    "\n",
    "\tprint(\"finish epoch {0} with mean loss {1}\".format(config.epoch, np.mean(losses_)))\n",
    "\treturn losses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAll(env: ReplayEnvironment, config: Config) -> ActorModel:\n",
    "\tmodel_ = ActorModel(env)\n",
    "\tepoch_ = config.epoch\n",
    "\t\n",
    "\tif epoch_ > 0:\n",
    "\t\tprint(\"loading checkpoint {0}\".format(epoch_))\n",
    "\t\tmodel_.load(config.stepCheckpoint())\n",
    "\telse:\n",
    "\t\tinitializePolicy(model_, env, config)\n",
    "\t\n",
    "\tfor t in range(epoch_, config.totalEpochs):\n",
    "\t\tprint(\"start training epoch {0}\".format(t))\n",
    "\t\tpath_ = config.stepCheckpoint(t)\n",
    "\t\tloss_ = trainModel(env, model_, config)\n",
    "\t\tprint(\"finish training, save to path {0}\".format(path_))\n",
    "\t\t#tc.save(model_.state_dict(), path_)\n",
    "\n",
    "\t\tprint(\"finish training epoch {0}\".format(t))\n",
    "\t\n",
    "\tprint(\"finish all training steps\")\n",
    "\treturn model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Config object at 0x0000021048620BE0>\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "initialization loss: 0.053715143352746964\n",
      "start training epoch 0\n",
      "begin epoch 0, path generation... \n",
      "begin epoch 0, training... \n",
      "finish epoch 0 with mean loss -0.31609181969951783\n",
      "finish training, save to path ./checkpoints/model_00.bin\n",
      "finish training epoch 0\n",
      "start training epoch 1\n",
      "begin epoch 1, path generation... \n",
      "begin epoch 1, training... \n",
      "finish epoch 1 with mean loss -0.24551071100462432\n",
      "finish training, save to path ./checkpoints/model_01.bin\n",
      "finish training epoch 1\n",
      "start training epoch 2\n",
      "begin epoch 2, path generation... \n",
      "begin epoch 2, training... \n",
      "finish epoch 2 with mean loss -0.4038170665886862\n",
      "finish training, save to path ./checkpoints/model_02.bin\n",
      "finish training epoch 2\n",
      "start training epoch 3\n",
      "begin epoch 3, path generation... \n",
      "begin epoch 3, training... \n",
      "finish epoch 3 with mean loss -0.24417520223051212\n",
      "finish training, save to path ./checkpoints/model_03.bin\n",
      "finish training epoch 3\n",
      "start training epoch 4\n",
      "begin epoch 4, path generation... \n",
      "begin epoch 4, training... \n",
      "finish epoch 4 with mean loss -0.4901747544914651\n",
      "finish training, save to path ./checkpoints/model_04.bin\n",
      "finish training epoch 4\n",
      "start training epoch 5\n",
      "begin epoch 5, path generation... \n",
      "begin epoch 5, training... \n",
      "finish epoch 5 with mean loss -0.2003934974932706\n",
      "finish training, save to path ./checkpoints/model_05.bin\n",
      "finish training epoch 5\n",
      "start training epoch 6\n",
      "begin epoch 6, path generation... \n",
      "begin epoch 6, training... \n",
      "finish epoch 6 with mean loss -0.15986052737659998\n",
      "finish training, save to path ./checkpoints/model_06.bin\n",
      "finish training epoch 6\n",
      "start training epoch 7\n",
      "begin epoch 7, path generation... \n",
      "begin epoch 7, training... \n",
      "finish epoch 7 with mean loss -0.23012300793963827\n",
      "finish training, save to path ./checkpoints/model_07.bin\n",
      "finish training epoch 7\n",
      "start training epoch 8\n",
      "begin epoch 8, path generation... \n",
      "begin epoch 8, training... \n",
      "finish epoch 8 with mean loss -0.684794332354857\n",
      "finish training, save to path ./checkpoints/model_08.bin\n",
      "finish training epoch 8\n",
      "start training epoch 9\n",
      "begin epoch 9, path generation... \n",
      "begin epoch 9, training... \n",
      "finish epoch 9 with mean loss -0.3156784224764428\n",
      "finish training, save to path ./checkpoints/model_09.bin\n",
      "finish training epoch 9\n",
      "start training epoch 10\n",
      "begin epoch 10, path generation... \n",
      "begin epoch 10, training... \n",
      "finish epoch 10 with mean loss -0.25101908107104776\n",
      "finish training, save to path ./checkpoints/model_10.bin\n",
      "finish training epoch 10\n",
      "start training epoch 11\n",
      "begin epoch 11, path generation... \n",
      "begin epoch 11, training... \n",
      "finish epoch 11 with mean loss 0.013013087055818705\n",
      "finish training, save to path ./checkpoints/model_11.bin\n",
      "finish training epoch 11\n",
      "start training epoch 12\n",
      "begin epoch 12, path generation... \n",
      "begin epoch 12, training... \n",
      "finish epoch 12 with mean loss -0.1088742511322556\n",
      "finish training, save to path ./checkpoints/model_12.bin\n",
      "finish training epoch 12\n",
      "start training epoch 13\n",
      "begin epoch 13, path generation... \n",
      "begin epoch 13, training... \n",
      "finish epoch 13 with mean loss -0.35507645389598486\n",
      "finish training, save to path ./checkpoints/model_13.bin\n",
      "finish training epoch 13\n",
      "start training epoch 14\n",
      "begin epoch 14, path generation... \n",
      "begin epoch 14, training... \n",
      "finish epoch 14 with mean loss -0.22169213097226514\n",
      "finish training, save to path ./checkpoints/model_14.bin\n",
      "finish training epoch 14\n",
      "start training epoch 15\n",
      "begin epoch 15, path generation... \n",
      "begin epoch 15, training... \n",
      "finish epoch 15 with mean loss -0.25485116720665246\n",
      "finish training, save to path ./checkpoints/model_15.bin\n",
      "finish training epoch 15\n",
      "start training epoch 16\n",
      "begin epoch 16, path generation... \n",
      "begin epoch 16, training... \n",
      "finish epoch 16 with mean loss -0.2731637094698317\n",
      "finish training, save to path ./checkpoints/model_16.bin\n",
      "finish training epoch 16\n",
      "start training epoch 17\n",
      "begin epoch 17, path generation... \n",
      "begin epoch 17, training... \n",
      "finish epoch 17 with mean loss 0.01650993213204819\n",
      "finish training, save to path ./checkpoints/model_17.bin\n",
      "finish training epoch 17\n",
      "start training epoch 18\n",
      "begin epoch 18, path generation... \n",
      "begin epoch 18, training... \n",
      "finish epoch 18 with mean loss 0.011021490675662967\n",
      "finish training, save to path ./checkpoints/model_18.bin\n",
      "finish training epoch 18\n",
      "start training epoch 19\n",
      "begin epoch 19, path generation... \n",
      "begin epoch 19, training... \n",
      "finish epoch 19 with mean loss 0.011319035048692081\n",
      "finish training, save to path ./checkpoints/model_19.bin\n",
      "finish training epoch 19\n",
      "start training epoch 20\n",
      "begin epoch 20, path generation... \n",
      "begin epoch 20, training... \n",
      "finish epoch 20 with mean loss 0.011129057407860453\n",
      "finish training, save to path ./checkpoints/model_20.bin\n",
      "finish training epoch 20\n",
      "start training epoch 21\n",
      "begin epoch 21, path generation... \n",
      "begin epoch 21, training... \n",
      "finish epoch 21 with mean loss 0.01071563362168124\n",
      "finish training, save to path ./checkpoints/model_21.bin\n",
      "finish training epoch 21\n",
      "start training epoch 22\n",
      "begin epoch 22, path generation... \n",
      "begin epoch 22, training... \n",
      "finish epoch 22 with mean loss 0.011414962620437539\n",
      "finish training, save to path ./checkpoints/model_22.bin\n",
      "finish training epoch 22\n",
      "start training epoch 23\n",
      "begin epoch 23, path generation... \n",
      "begin epoch 23, training... \n",
      "finish epoch 23 with mean loss 0.007542381097729771\n",
      "finish training, save to path ./checkpoints/model_23.bin\n",
      "finish training epoch 23\n",
      "start training epoch 24\n",
      "begin epoch 24, path generation... \n",
      "begin epoch 24, training... \n",
      "finish epoch 24 with mean loss -0.08577448015530724\n",
      "finish training, save to path ./checkpoints/model_24.bin\n",
      "finish training epoch 24\n",
      "start training epoch 25\n",
      "begin epoch 25, path generation... \n",
      "begin epoch 25, training... \n",
      "finish epoch 25 with mean loss -0.010172520118531274\n",
      "finish training, save to path ./checkpoints/model_25.bin\n",
      "finish training epoch 25\n",
      "start training epoch 26\n",
      "begin epoch 26, path generation... \n",
      "begin epoch 26, training... \n",
      "finish epoch 26 with mean loss 0.011550874562112626\n",
      "finish training, save to path ./checkpoints/model_26.bin\n",
      "finish training epoch 26\n",
      "start training epoch 27\n",
      "begin epoch 27, path generation... \n",
      "begin epoch 27, training... \n",
      "finish epoch 27 with mean loss -0.06789567786808076\n",
      "finish training, save to path ./checkpoints/model_27.bin\n",
      "finish training epoch 27\n",
      "start training epoch 28\n",
      "begin epoch 28, path generation... \n",
      "begin epoch 28, training... \n",
      "finish epoch 28 with mean loss 0.010025029657592006\n",
      "finish training, save to path ./checkpoints/model_28.bin\n",
      "finish training epoch 28\n",
      "start training epoch 29\n",
      "begin epoch 29, path generation... \n",
      "begin epoch 29, training... \n",
      "finish epoch 29 with mean loss -0.022029146760168795\n",
      "finish training, save to path ./checkpoints/model_29.bin\n",
      "finish training epoch 29\n",
      "start training epoch 30\n",
      "begin epoch 30, path generation... \n",
      "begin epoch 30, training... \n",
      "finish epoch 30 with mean loss 0.006317460181740805\n",
      "finish training, save to path ./checkpoints/model_30.bin\n",
      "finish training epoch 30\n",
      "start training epoch 31\n",
      "begin epoch 31, path generation... \n",
      "begin epoch 31, training... \n",
      "finish epoch 31 with mean loss -0.02791616216289823\n",
      "finish training, save to path ./checkpoints/model_31.bin\n",
      "finish training epoch 31\n",
      "start training epoch 32\n",
      "begin epoch 32, path generation... \n",
      "begin epoch 32, training... \n",
      "finish epoch 32 with mean loss -0.053132144963277166\n",
      "finish training, save to path ./checkpoints/model_32.bin\n",
      "finish training epoch 32\n",
      "start training epoch 33\n",
      "begin epoch 33, path generation... \n",
      "begin epoch 33, training... \n",
      "finish epoch 33 with mean loss 0.011840480976662208\n",
      "finish training, save to path ./checkpoints/model_33.bin\n",
      "finish training epoch 33\n",
      "start training epoch 34\n",
      "begin epoch 34, path generation... \n",
      "begin epoch 34, training... \n",
      "finish epoch 34 with mean loss 0.001463680742502523\n",
      "finish training, save to path ./checkpoints/model_34.bin\n",
      "finish training epoch 34\n",
      "start training epoch 35\n",
      "begin epoch 35, path generation... \n",
      "begin epoch 35, training... \n",
      "finish epoch 35 with mean loss 0.0057503083791536624\n",
      "finish training, save to path ./checkpoints/model_35.bin\n",
      "finish training epoch 35\n",
      "start training epoch 36\n",
      "begin epoch 36, path generation... \n",
      "begin epoch 36, training... \n",
      "finish epoch 36 with mean loss 0.004496730118632431\n",
      "finish training, save to path ./checkpoints/model_36.bin\n",
      "finish training epoch 36\n",
      "start training epoch 37\n",
      "begin epoch 37, path generation... \n",
      "begin epoch 37, training... \n",
      "finish epoch 37 with mean loss -0.010577737230151516\n",
      "finish training, save to path ./checkpoints/model_37.bin\n",
      "finish training epoch 37\n",
      "start training epoch 38\n",
      "begin epoch 38, path generation... \n",
      "begin epoch 38, training... \n",
      "finish epoch 38 with mean loss -0.0039460963737750635\n",
      "finish training, save to path ./checkpoints/model_38.bin\n",
      "finish training epoch 38\n",
      "start training epoch 39\n",
      "begin epoch 39, path generation... \n",
      "begin epoch 39, training... \n",
      "finish epoch 39 with mean loss -0.11159881714537717\n",
      "finish training, save to path ./checkpoints/model_39.bin\n",
      "finish training epoch 39\n",
      "start training epoch 40\n",
      "begin epoch 40, path generation... \n",
      "begin epoch 40, training... \n",
      "finish epoch 40 with mean loss -0.1521803757951818\n",
      "finish training, save to path ./checkpoints/model_40.bin\n",
      "finish training epoch 40\n",
      "start training epoch 41\n",
      "begin epoch 41, path generation... \n",
      "begin epoch 41, training... \n",
      "finish epoch 41 with mean loss -0.1580211444270479\n",
      "finish training, save to path ./checkpoints/model_41.bin\n",
      "finish training epoch 41\n",
      "start training epoch 42\n",
      "begin epoch 42, path generation... \n",
      "begin epoch 42, training... \n",
      "finish epoch 42 with mean loss 0.015780567432847472\n",
      "finish training, save to path ./checkpoints/model_42.bin\n",
      "finish training epoch 42\n",
      "start training epoch 43\n",
      "begin epoch 43, path generation... \n",
      "begin epoch 43, training... \n",
      "finish epoch 43 with mean loss 0.0072842591598676325\n",
      "finish training, save to path ./checkpoints/model_43.bin\n",
      "finish training epoch 43\n",
      "start training epoch 44\n",
      "begin epoch 44, path generation... \n",
      "begin epoch 44, training... \n",
      "finish epoch 44 with mean loss 0.006708288581871774\n",
      "finish training, save to path ./checkpoints/model_44.bin\n",
      "finish training epoch 44\n",
      "start training epoch 45\n",
      "begin epoch 45, path generation... \n",
      "begin epoch 45, training... \n",
      "finish epoch 45 with mean loss -0.007351872655276285\n",
      "finish training, save to path ./checkpoints/model_45.bin\n",
      "finish training epoch 45\n",
      "start training epoch 46\n",
      "begin epoch 46, path generation... \n",
      "begin epoch 46, training... \n",
      "finish epoch 46 with mean loss 0.0061096733801865154\n",
      "finish training, save to path ./checkpoints/model_46.bin\n",
      "finish training epoch 46\n",
      "start training epoch 47\n",
      "begin epoch 47, path generation... \n",
      "begin epoch 47, training... \n",
      "finish epoch 47 with mean loss -0.0005682788524978065\n",
      "finish training, save to path ./checkpoints/model_47.bin\n",
      "finish training epoch 47\n",
      "start training epoch 48\n",
      "begin epoch 48, path generation... \n",
      "begin epoch 48, training... \n",
      "finish epoch 48 with mean loss 0.007605540946790662\n",
      "finish training, save to path ./checkpoints/model_48.bin\n",
      "finish training epoch 48\n",
      "start training epoch 49\n",
      "begin epoch 49, path generation... \n",
      "begin epoch 49, training... \n",
      "finish epoch 49 with mean loss -0.024096344223063802\n",
      "finish training, save to path ./checkpoints/model_49.bin\n",
      "finish training epoch 49\n",
      "finish all training steps\n",
      "tensor([0.0392, 0.0344, 0.0591, 0.0363, 0.0636, 0.0262, 0.0834, 0.0180, 0.0818,\n",
      "        0.1794, 0.2207, 0.0321, 0.0327, 0.3435, 0.6541, 0.0299],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\tconfig_ = Config(0, False)\n",
    "\tenv_ = ReplayEnvironment(config_)\n",
    "\tmodel_ = trainAll(env_, config_)\n",
    "\t_, est_ = model_(tc.arange(0, env_.stateSpace))\n",
    "\tprint(est_)\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PPO_PONG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2cb1ba66c70c9f1b4bc3712c3a7c9a4b0257feab7a6813209c9ff0ab78fb2ef6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
